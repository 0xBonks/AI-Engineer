{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 04 - Notebook 01: Hugging Face Hub\n",
    "\n",
    "## Learning Objectives\n",
    "- Navigate Hugging Face Hub to find models\n",
    "- Understand model cards and documentation\n",
    "- Compare different open source models\n",
    "- Select appropriate models for tasks\n",
    "\n",
    "## Prerequisites\n",
    "- Hugging Face account (free): https://huggingface.co/join\n",
    "- HF token (get from https://huggingface.co/settings/tokens)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Authentication\n",
    "\n",
    "First, let's install the Hugging Face Hub library and set up authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q huggingface-hub python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi, list_models, model_info\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get your HF token from .env file or set it here\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    print(\"‚ö†Ô∏è Warning: HUGGINGFACE_TOKEN not found in .env file\")\n",
    "    print(\"Get your token from: https://huggingface.co/settings/tokens\")\n",
    "else:\n",
    "    print(\"‚úì Token loaded successfully\")\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Browsing Models\n",
    "\n",
    "Let's explore popular text generation models on Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List popular text generation models\n",
    "print(\"Top 10 Text Generation Models by Downloads:\\n\")\n",
    "\n",
    "models = list_models(\n",
    "    filter=\"text-generation\",\n",
    "    sort=\"downloads\",\n",
    "    direction=-1,\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "for i, model in enumerate(models, 1):\n",
    "    print(f\"{i}. {model.id}\")\n",
    "    print(f\"   Downloads: {model.downloads:,}\")\n",
    "    print(f\"   Likes: {model.likes}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading Model Cards\n",
    "\n",
    "Model cards contain crucial information about a model's capabilities, limitations, and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed info about a specific model\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "try:\n",
    "    info = model_info(model_name)\n",
    "    \n",
    "    print(f\"Model: {info.id}\")\n",
    "    print(f\"Author: {info.author}\")\n",
    "    print(f\"Downloads: {info.downloads:,}\")\n",
    "    print(f\"Likes: {info.likes}\")\n",
    "    print(f\"\\nTags: {', '.join(info.tags[:10])}\")\n",
    "    print(f\"\\nLibrary: {info.library_name}\")\n",
    "    print(f\"Pipeline Tag: {info.pipeline_tag}\")\n",
    "    \n",
    "    if info.card_data:\n",
    "        print(f\"\\nLicense: {info.card_data.license}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Note: You may need authentication for some models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing Models\n",
    "\n",
    "Let's compare several popular open source LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Models to compare\n",
    "models_to_compare = [\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    \"google/gemma-2b-it\",\n",
    "]\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    try:\n",
    "        info = model_info(model_name)\n",
    "        comparison_data.append({\n",
    "            \"Model\": info.id.split(\"/\")[-1],\n",
    "            \"Organization\": info.author,\n",
    "            \"Downloads\": info.downloads,\n",
    "            \"Likes\": info.likes,\n",
    "            \"License\": info.card_data.license if info.card_data else \"Unknown\",\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch {model_name}: {e}\")\n",
    "\n",
    "# Display comparison\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Searching by Task\n",
    "\n",
    "Find models for specific tasks like summarization, translation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for summarization models\n",
    "print(\"Top 5 Summarization Models:\\n\")\n",
    "\n",
    "summarization_models = list_models(\n",
    "    filter=\"summarization\",\n",
    "    sort=\"downloads\",\n",
    "    direction=-1,\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "for i, model in enumerate(summarization_models, 1):\n",
    "    print(f\"{i}. {model.id}\")\n",
    "    print(f\"   Downloads: {model.downloads:,}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Selection Criteria\n",
    "\n",
    "When choosing a model, consider:\n",
    "\n",
    "### Size\n",
    "- **Small (< 3B)**: Fast, low memory, good for simple tasks\n",
    "- **Medium (3-13B)**: Balanced performance and resource usage\n",
    "- **Large (> 13B)**: Best quality, requires significant resources\n",
    "\n",
    "### License\n",
    "- **MIT/Apache 2.0**: Permissive, commercial use OK\n",
    "- **Llama License**: Restrictions on commercial use for large companies\n",
    "- **Gemma License**: Google-specific terms\n",
    "\n",
    "### Performance Metrics\n",
    "- Check benchmarks (MMLU, HumanEval, etc.)\n",
    "- Review community feedback\n",
    "- Test on your specific use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Find a Model for Your Use Case\n",
    "\n",
    "Complete the following task:\n",
    "\n",
    "1. Choose a task (e.g., code generation, creative writing, Q&A)\n",
    "2. Find 3 suitable models\n",
    "3. Compare their licenses, sizes, and popularity\n",
    "4. Document your choice and reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete this exercise\n",
    "# Your task: \"______\"\n",
    "# Your top 3 models:\n",
    "# 1. ______\n",
    "# 2. ______\n",
    "# 3. ______\n",
    "# Your final choice: ______\n",
    "# Reasoning: ______\n",
    "\n",
    "# Write your code here to research and compare models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- ‚úÖ How to authenticate with Hugging Face Hub\n",
    "- ‚úÖ How to browse and search for models\n",
    "- ‚úÖ How to read model cards and compare models\n",
    "- ‚úÖ Model selection criteria\n",
    "\n",
    "## Next Steps\n",
    "- üìò Proceed to Notebook 02: Inference SDK\n",
    "- üîó Explore the [Hugging Face Model Hub](https://huggingface.co/models)\n",
    "- üìö Read about [model licensing](https://huggingface.co/docs/hub/model-cards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
