{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Phase 2 Integration - Complete Example\n\n## Production-Ready AI Client\n\nThis notebook demonstrates all Phase 2 concepts together:\n- Async programming\n- Type safety with Pydantic\n- Error handling and logging\n- Decorators and classes\n\n## Complete Example"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import asyncio\nimport logging\nfrom typing import List, Optional\nfrom pydantic import BaseModel\nfrom openai import AsyncOpenAI\n\nclass ChatResponse(BaseModel):\n    '''Typed response model.'''\n    content: str\n    tokens: int\n    model: str\n\nclass ProductionAIClient:\n    '''Production-ready AI client with all patterns.'''\n    \n    def __init__(self, api_key: str, max_concurrent: int = 5):\n        self.client = AsyncOpenAI(api_key=api_key)\n        self.semaphore = asyncio.Semaphore(max_concurrent)\n        self.logger = logging.getLogger(__name__)\n    \n    async def generate(self, prompt: str) -> Optional[ChatResponse]:\n        '''Generate with error handling, retries, logging.'''\n        async with self.semaphore:\n            try:\n                response = await self.client.chat.completions.create(\n                    model='gpt-3.5-turbo',\n                    messages=[{'role': 'user', 'content': prompt}]\n                )\n                \n                return ChatResponse(\n                    content=response.choices[0].message.content,\n                    tokens=response.usage.total_tokens,\n                    model=response.model\n                )\n            \n            except Exception as e:\n                self.logger.error(f'Error: {e}')\n                return None\n\nprint('âœ… All Phase 2 patterns integrated!')"]}], "metadata": {"kernelspec": {"display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 4}
