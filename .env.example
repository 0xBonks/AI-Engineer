# ==============================================================================
# AI Engineer Learning Repository - Environment Configuration
# ==============================================================================
# 
# IMPORTANT: This is a template file. To use it:
#   1. Copy this file: cp .env.example .env
#   2. Fill in your actual API keys and configuration
#   3. Never commit .env to version control (already in .gitignore)
#
# ==============================================================================

# ------------------------------------------------------------------------------
# OpenAI API Configuration (Required)
# ------------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# Pricing: https://openai.com/pricing
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI Organization ID (optional - only if you have multiple orgs)
# OPENAI_ORG_ID=org-your-organization-id

# ------------------------------------------------------------------------------
# Anthropic API Configuration (Optional - for model comparisons)
# ------------------------------------------------------------------------------
# Get your API key from: https://console.anthropic.com/
# Pricing: https://www.anthropic.com/pricing
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# ------------------------------------------------------------------------------
# LiteLLM Configuration (Optional - unified interface for multiple providers)
# ------------------------------------------------------------------------------
# LiteLLM provides a unified API for OpenAI, Anthropic, Azure, Google, and more.
# It automatically reads the API keys above (OPENAI_API_KEY, ANTHROPIC_API_KEY, etc.)
# No additional configuration needed - just set the provider-specific API keys!
#
# Supported providers:
# - OpenAI: Use model names like "gpt-3.5-turbo", "gpt-4"
# - Anthropic: Use model names like "claude-3-opus-20240229", "claude-3-sonnet-20240229"
# - Azure OpenAI: Use model names like "azure/<deployment-name>"
# - Google: Use model names like "gemini-pro"
#
# For Azure OpenAI, additional configuration is required:
# AZURE_API_KEY=your-azure-api-key-here
# AZURE_API_BASE=https://your-resource.openai.azure.com/
# AZURE_API_VERSION=2024-02-15-preview
#
# LiteLLM features:
# - Automatic retry logic and rate limiting
# - Built-in cost tracking across providers
# - Easy model switching without code changes
# - Streaming support for all providers
#
# Example usage in utils/litellm_helpers.py

# ------------------------------------------------------------------------------
# Google Generative AI (Gemini) Configuration (Optional)
# ------------------------------------------------------------------------------
# Get your API key from: https://makersuite.google.com/app/apikey
# GOOGLE_API_KEY=your-google-api-key-here

# ------------------------------------------------------------------------------
# Hugging Face Configuration (Optional - for model downloads)
# ------------------------------------------------------------------------------
# Get your API key from: https://huggingface.co/settings/tokens
# Required for: Downloading gated models, using Inference API
# HUGGINGFACE_API_KEY=hf_your-huggingface-token-here

# ------------------------------------------------------------------------------
# Pinecone Vector Database (Optional - used in advanced modules)
# ------------------------------------------------------------------------------
# Get your API key from: https://app.pinecone.io/
# Free tier available: https://www.pinecone.io/pricing/
# PINECONE_API_KEY=your-pinecone-api-key-here
# PINECONE_ENVIRONMENT=us-west1-gcp  # Your Pinecone environment

# ------------------------------------------------------------------------------
# Weaviate Vector Database (Optional - alternative to Chroma)
# ------------------------------------------------------------------------------
# Get credentials from: https://console.weaviate.cloud/
# Free sandbox available
# WEAVIATE_URL=https://your-cluster.weaviate.network
# WEAVIATE_API_KEY=your-weaviate-api-key-here

# ------------------------------------------------------------------------------
# Application Configuration
# ------------------------------------------------------------------------------

# Logging Configuration
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json  # Options: json, text

# Cost Tracking
COST_TRACKING_ENABLED=true  # Enable/disable API cost tracking
COST_WARNING_THRESHOLD=10.0  # Warn when session costs exceed this amount (USD)
COST_MAX_THRESHOLD=50.0  # Block execution if costs exceed this amount (USD)

# Model Defaults
DEFAULT_CHAT_MODEL=gpt-3.5-turbo  # Default model for chat completions
DEFAULT_EMBEDDING_MODEL=text-embedding-3-small  # Default embedding model
DEFAULT_TEMPERATURE=0.7  # Default temperature for completions (0.0-2.0)
DEFAULT_MAX_TOKENS=1000  # Default max tokens for completions

# API Rate Limiting
MAX_REQUESTS_PER_MINUTE=60  # Maximum API requests per minute
MAX_CONCURRENT_REQUESTS=5  # Maximum concurrent API requests

# Development Settings
DEBUG_MODE=false  # Enable debug mode for verbose logging
CACHE_ENABLED=true  # Enable response caching for development
CACHE_DIR=.cache  # Directory for cached responses

# ------------------------------------------------------------------------------
# Vector Database Configuration (Chroma)
# ------------------------------------------------------------------------------
CHROMA_PERSIST_DIRECTORY=./data/chroma  # Local storage for Chroma DB
CHROMA_COLLECTION_NAME=ai_engineer_learning  # Default collection name

# ------------------------------------------------------------------------------
# Jupyter Configuration
# ------------------------------------------------------------------------------
JUPYTER_PORT=8888  # Port for JupyterLab
JUPYTER_TOKEN=  # Leave empty for no token (development only)

# ------------------------------------------------------------------------------
# Docker Configuration (if using Docker environment)
# ------------------------------------------------------------------------------
DOCKER_GPU_ENABLED=false  # Enable GPU support in Docker (requires nvidia-docker)
DOCKER_PORT=8888  # Exposed port for JupyterLab

# ==============================================================================
# Security Notes:
# ==============================================================================
# 1. NEVER commit .env file to version control
# 2. Rotate API keys regularly (every 90 days recommended)
# 3. Use separate API keys for development and production
# 4. Monitor API usage for unexpected activity
# 5. Enable cost limits in your API provider dashboards
# 6. Review API key permissions (use least privilege)
#
# If API key is compromised:
#   1. Immediately revoke the key in provider dashboard
#   2. Generate new key
#   3. Update .env file
#   4. Review recent API usage for abuse
# ==============================================================================

# ==============================================================================
# Cost Management Tips:
# ==============================================================================
# 1. Start with GPT-3.5-turbo for learning (much cheaper than GPT-4)
# 2. Use smaller embedding models when possible
# 3. Implement request caching for repeated queries
# 4. Set cost limits in OpenAI dashboard
# 5. Monitor usage with built-in cost tracking utilities
# 6. Use local models (Ollama) for experimentation
#
# Estimated costs for complete repository: $50-150
# Most expensive modules: Module 10 (Portfolio Projects)
# ==============================================================================
