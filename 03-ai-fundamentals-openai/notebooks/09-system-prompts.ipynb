{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# System Prompts\n\n",
        "System prompts are instructions that guide the assistant's behavior throughout the conversation.\n\n",
        "## Why System Prompts Matter\n\n",
        "System prompts:\n",
        "- Set the assistant's role and personality\n",
        "- Control output format and style\n",
        "- Define constraints and guidelines\n",
        "- Persist across all turns in conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n\n",
        "load_dotenv()\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: No System Prompt vs With System Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_question = \"What is Python?\"\n\n",
        "# Without system prompt\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": user_question}]\n",
        ")\n",
        "print(\"WITHOUT system prompt:\")\n",
        "print(response1.choices[0].message.content)\n\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n\n",
        "# With system prompt\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You explain technical concepts to 5-year-olds using simple words and fun analogies.\"},\n",
        "        {\"role\": \"user\", \"content\": user_question}\n",
        "    ]\n",
        ")\n",
        "print(\"WITH system prompt (explain to 5-year-old):\")\n",
        "print(response2.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Setting Role and Personality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_personality(user_msg: str, personality: str):\n",
        "    \"\"\"Chat with different personalities.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": personality},\n",
        "            {\"role\": \"user\", \"content\": user_msg}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n\n",
        "question = \"Should I learn Python or JavaScript first?\"\n\n",
        "# Personality 1: Professional consultant\n",
        "print(\"üé© PROFESSIONAL CONSULTANT:\")\n",
        "print(chat_with_personality(\n",
        "    question,\n",
        "    \"You are a professional tech career consultant. Be analytical, data-driven, and professional.\"\n",
        "))\n\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n\n",
        "# Personality 2: Enthusiastic friend\n",
        "print(\"üéâ ENTHUSIASTIC FRIEND:\")\n",
        "print(chat_with_personality(\n",
        "    question,\n",
        "    \"You are a super enthusiastic coding buddy! Use lots of exclamation marks and be very encouraging!\"\n",
        "))\n\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n\n",
        "# Personality 3: Pirate\n",
        "print(\"üè¥‚Äç‚ò†Ô∏è PIRATE:\")\n",
        "print(chat_with_personality(\n",
        "    question,\n",
        "    \"You are a pirate captain who loves coding. Speak like a pirate and use sailing metaphors.\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Controlling Output Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic = \"machine learning\"\n\n",
        "# Format 1: Bullet points\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Always respond with exactly 3 bullet points. Be concise.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Explain {topic}\"}\n",
        "    ]\n",
        ")\n",
        "print(\"üìù BULLET POINTS:\")\n",
        "print(response1.choices[0].message.content)\n\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n\n",
        "# Format 2: Numbered steps\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Always respond with numbered steps (1. 2. 3. etc.). Each step should be one short sentence.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Explain {topic}\"}\n",
        "    ]\n",
        ")\n",
        "print(\"üî¢ NUMBERED STEPS:\")\n",
        "print(response2.choices[0].message.content)\n\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n\n",
        "# Format 3: Table\n",
        "response3 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Always respond with a markdown table format with columns: Concept | Description | Example\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Explain key concepts of {topic}\"}\n",
        "    ]\n",
        ")\n",
        "print(\"üìä TABLE FORMAT:\")\n",
        "print(response3.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Setting Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constraint 1: Length limit\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You must answer in exactly one sentence. Never use more than one sentence.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain neural networks\"}\n",
        "    ]\n",
        ")\n",
        "print(\"ONE SENTENCE LIMIT:\")\n",
        "print(response1.choices[0].message.content)\n",
        "print(f\"({response1.choices[0].message.content.count('.')} sentences)\\n\")\n\n",
        "# Constraint 2: Word limit\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Respond in exactly 20 words. Count carefully.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is deep learning?\"}\n",
        "    ]\n",
        ")\n",
        "print(\"20 WORD LIMIT:\")\n",
        "answer = response2.choices[0].message.content\n",
        "print(answer)\n",
        "print(f\"({len(answer.split())} words)\\n\")\n\n",
        "# Constraint 3: Vocabulary level\n",
        "response3 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Only use simple words that a 10-year-old would understand. Avoid technical jargon.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is an algorithm?\"}\n",
        "    ]\n",
        ")\n",
        "print(\"SIMPLE VOCABULARY:\")\n",
        "print(response3.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 5: Domain Expert System Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code reviewer\n",
        "code_review_prompt = \"\"\"\n",
        "You are an expert code reviewer. Analyze code for:\n",
        "- Bugs and errors\n",
        "- Performance issues\n",
        "- Security vulnerabilities\n",
        "- Code style and best practices\n",
        "\n",
        "Format your review as:\n",
        "1. Issues (numbered list)\n",
        "2. Suggestions (numbered list)\n",
        "3. Overall rating (1-10)\n",
        "\"\"\"\n\n",
        "code = \"\"\"\n",
        "def calculate_average(numbers):\n",
        "    total = 0\n",
        "    for num in numbers:\n",
        "        total = total + num\n",
        "    return total / len(numbers)\n",
        "\"\"\"\n\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": code_review_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Review this code:\\n{code}\"}\n",
        "    ]\n",
        ")\n",
        "print(\"CODE REVIEW:\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for System Prompts\n\n",
        "### ‚úÖ DO:\n",
        "1. **Be specific and clear** about what you want\n",
        "2. **Define the role** explicitly (\"You are a...\")\n",
        "3. **Specify format** if you need structured output\n",
        "4. **Set boundaries** (what NOT to do)\n",
        "5. **Keep it concise** but comprehensive\n\n",
        "### ‚ùå DON'T:\n",
        "1. Make system prompts too long (wastes tokens)\n",
        "2. Contradict yourself\n",
        "3. Ask questions in system prompts (use user messages)\n",
        "4. Forget system prompts are NOT seen by end users\n",
        "5. Change system prompts mid-conversation (start new conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Prompt Templates\n\n",
        "### Template 1: Customer Support Bot\n",
        "```\n",
        "You are a helpful customer support agent for [COMPANY].\n",
        "- Be polite, professional, and empathetic\n",
        "- If you don't know something, say so and offer to escalate\n",
        "- Keep responses under 100 words\n",
        "- Never make promises about refunds or discounts without approval\n",
        "```\n\n",
        "### Template 2: Educational Tutor\n",
        "```\n",
        "You are a patient tutor for [SUBJECT].\n",
        "- Explain concepts step-by-step\n",
        "- Use examples and analogies\n",
        "- Ask follow-up questions to check understanding\n",
        "- Encourage the student when they're struggling\n",
        "- Never give direct answers to homework problems\n",
        "```\n\n",
        "### Template 3: Technical Expert\n",
        "```\n",
        "You are an expert in [TECHNOLOGY].\n",
        "- Provide accurate, technical information\n",
        "- Include code examples when relevant\n",
        "- Cite best practices and common patterns\n",
        "- Warn about potential pitfalls\n",
        "- Assume the user has intermediate knowledge\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice Exercises\n\n",
        "1. Create a system prompt that makes the AI respond only in haiku format\n",
        "2. Build a personality that combines two opposite traits (e.g., formal but funny)\n",
        "3. Design a system prompt that enforces JSON output format\n",
        "4. Create a multi-constraint prompt (role + format + length + style)\n",
        "5. Test how system prompts affect responses across multiple conversation turns"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
