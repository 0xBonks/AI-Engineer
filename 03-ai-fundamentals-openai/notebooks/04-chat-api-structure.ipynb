{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chat Completions API Structure\n\n",
        "## Overview\n\n",
        "The OpenAI Chat Completions API is the primary interface for interacting with models like GPT-4 and GPT-3.5 Turbo.\n\n",
        "**Key Concept:** You send *messages* (not just text) and get structured *responses*.\n\n",
        "## Message Roles\n\n",
        "### System Message\n",
        "- Sets the behavior and personality of the assistant\n",
        "- Optional but recommended\n",
        "- Processed first, influences all responses\n\n",
        "```python\n",
        "{\"role\": \"system\", \"content\": \"You are a helpful assistant that speaks like a pirate.\"}\n",
        "```\n\n",
        "### User Message\n",
        "- Your input/question\n",
        "- Required\n",
        "- Represents the human's side of conversation\n\n",
        "```python\n",
        "{\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "```\n\n",
        "### Assistant Message\n",
        "- The AI's response\n",
        "- Used for conversation history\n",
        "- Returned by API or added manually for context\n\n",
        "```python\n",
        "{\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Structure\n\n",
        "### Required Parameters\n\n",
        "```python\n",
        "{\n",
        "    \"model\": \"gpt-3.5-turbo\",  # Which model to use\n",
        "    \"messages\": [               # Array of message objects\n",
        "        {\"role\": \"system\", \"content\": \"...\"},\n",
        "        {\"role\": \"user\", \"content\": \"...\"}\n",
        "    ]\n",
        "}\n",
        "```\n\n",
        "### Common Optional Parameters\n\n",
        "```python\n",
        "{\n",
        "    \"temperature\": 1.0,      # 0-2: Randomness (default: 1)\n",
        "    \"max_tokens\": 100,       # Max response length\n",
        "    \"top_p\": 1.0,           # Nucleus sampling (default: 1)\n",
        "    \"n\": 1,                 # Number of responses (default: 1)\n",
        "    \"stop\": [\"\\n\"],         # Stop sequences\n",
        "    \"presence_penalty\": 0,   # -2 to 2: Encourage new topics\n",
        "    \"frequency_penalty\": 0   # -2 to 2: Reduce repetition\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Response Structure\n\n",
        "### Successful Response\n\n",
        "```python\n",
        "{\n",
        "    \"id\": \"chatcmpl-123\",\n",
        "    \"object\": \"chat.completion\",\n",
        "    \"created\": 1677652288,\n",
        "    \"model\": \"gpt-3.5-turbo-0613\",\n",
        "    \"choices\": [\n",
        "        {\n",
        "            \"index\": 0,\n",
        "            \"message\": {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"The capital of France is Paris.\"\n",
        "            },\n",
        "            \"finish_reason\": \"stop\"  # stop, length, content_filter\n",
        "        }\n",
        "    ],\n",
        "    \"usage\": {\n",
        "        \"prompt_tokens\": 13,\n",
        "        \"completion_tokens\": 7,\n",
        "        \"total_tokens\": 20\n",
        "    }\n",
        "}\n",
        "```\n\n",
        "### Key Fields\n\n",
        "- **choices[0].message.content**: The actual response text\n",
        "- **usage**: Token counts for cost tracking\n",
        "- **finish_reason**:\n",
        "  - `stop`: Natural completion\n",
        "  - `length`: Hit max_tokens limit\n",
        "  - `content_filter`: Flagged by moderation\n",
        "  - `tool_calls`: Model wants to call a function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authentication\n\n",
        "### API Key Setup\n\n",
        "```python\n",
        "import os\n",
        "from openai import OpenAI\n\n",
        "# Method 1: Environment variable (recommended)\n",
        "# Set OPENAI_API_KEY in your .env file\n",
        "client = OpenAI()  # Automatically uses OPENAI_API_KEY env var\n\n",
        "# Method 2: Explicit key (not recommended for production)\n",
        "client = OpenAI(api_key=\"sk-...\")\n",
        "```\n\n",
        "### Best Practices\n\n",
        "1. **Never hardcode API keys** in source code\n",
        "2. **Use environment variables** (.env file)\n",
        "3. **Never commit .env** to git (add to .gitignore)\n",
        "4. **Rotate keys** if accidentally exposed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Basic Request\n\n",
        "```python\n",
        "from openai import OpenAI\n\n",
        "client = OpenAI()\n\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=50\n",
        ")\n\n",
        "# Extract the response\n",
        "answer = response.choices[0].message.content\n",
        "print(answer)  # \"2 + 2 equals 4.\"\n\n",
        "# Check token usage\n",
        "print(f\"Used {response.usage.total_tokens} tokens\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Selection\n\n",
        "### Available Models\n\n",
        "| Model | Best For | Speed | Cost |\n",
        "|-------|----------|-------|------|\n",
        "| gpt-4-turbo-preview | Complex tasks | Slow | High |\n",
        "| gpt-4 | Accuracy critical | Slow | High |\n",
        "| gpt-3.5-turbo | Most tasks | Fast | Low |\n",
        "| gpt-3.5-turbo-16k | Longer context | Fast | Low |\n\n",
        "### How to Choose\n\n",
        "- **Start with gpt-3.5-turbo** for development\n",
        "- **Upgrade to gpt-4** if results insufficient\n",
        "- **Use gpt-4 for demos** where quality matters\n",
        "- **Stick with 3.5 for production** to control costs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n\n",
        "Now that you understand the API structure, let's:\n",
        "1. Make your first API call (next notebook)\n",
        "2. Handle errors properly\n",
        "3. Build conversation patterns\n",
        "4. Add streaming for better UX"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
