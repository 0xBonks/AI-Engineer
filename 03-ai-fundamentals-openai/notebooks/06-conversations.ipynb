{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Turn Conversations\n\n",
        "Learn to maintain conversation context and build chatbots!\n\n",
        "## The Problem\n\n",
        "Each API call is stateless - the model doesn't remember previous messages.\n\n",
        "**Solution:** Send conversation history with each request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n\n",
        "load_dotenv()\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Two-Turn Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First turn\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"My name is Alice.\"}\n",
        "]\n\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages\n",
        ")\n\n",
        "assistant_reply = response.choices[0].message.content\n",
        "print(\"Assistant:\", assistant_reply)\n\n",
        "# Add assistant's response to history\n",
        "messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n\n",
        "# Second turn - model now knows previous context\n",
        "messages.append({\"role\": \"user\", \"content\": \"What's my name?\"})\n\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages\n",
        ")\n\n",
        "print(\"\\nAssistant:\", response.choices[0].message.content)  # Should say \"Alice\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Conversation Manager Class\n\n",
        "Let's build a reusable conversation manager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConversationManager:\n",
        "    def __init__(self, system_prompt: str = \"You are a helpful assistant.\", model: str = \"gpt-3.5-turbo\"):\n",
        "        self.model = model\n",
        "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "        self.client = OpenAI()\n",
        "    \n",
        "    def send(self, user_message: str) -> str:\n",
        "        \"\"\"Send a message and get response.\"\"\"\n",
        "        # Add user message\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        \n",
        "        # Get response\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=self.messages\n",
        "        )\n",
        "        \n",
        "        # Add assistant response to history\n",
        "        assistant_message = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        \n",
        "        return assistant_message\n",
        "    \n",
        "    def get_history(self):\n",
        "        \"\"\"Return conversation history.\"\"\"\n",
        "        return self.messages\n",
        "    \n",
        "    def clear(self):\n",
        "        \"\"\"Clear conversation history (keeps system prompt).\"\"\"\n",
        "        system_msg = self.messages[0]\n",
        "        self.messages = [system_msg]\n\n",
        "# Test it\n",
        "conv = ConversationManager()\n",
        "\n",
        "print(\"User: I love programming.\")\n",
        "print(\"Assistant:\", conv.send(\"I love programming.\"))\n",
        "\n",
        "print(\"\\nUser: What do I love?\")\n",
        "print(\"Assistant:\", conv.send(\"What do I love?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context Window Management\n\n",
        "Problem: Conversations can exceed the context window!\n\n",
        "**Solution strategies:**\n",
        "1. Truncate old messages\n",
        "2. Summarize conversation periodically\n",
        "3. Use sliding window (keep recent N messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n\n",
        "class SmartConversationManager:\n",
        "    def __init__(self, system_prompt: str = \"You are a helpful assistant.\", \n",
        "                 model: str = \"gpt-3.5-turbo\",\n",
        "                 max_tokens: int = 4000):  # Reserve tokens for context\n",
        "        self.model = model\n",
        "        self.max_tokens = max_tokens\n",
        "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "        self.client = OpenAI()\n",
        "        self.encoding = tiktoken.encoding_for_model(model)\n",
        "    \n",
        "    def count_tokens(self) -> int:\n",
        "        \"\"\"Count tokens in current conversation.\"\"\"\n",
        "        total = 0\n",
        "        for msg in self.messages:\n",
        "            total += len(self.encoding.encode(msg[\"content\"]))\n",
        "        return total\n",
        "    \n",
        "    def trim_history(self):\n",
        "        \"\"\"Remove old messages if exceeding token limit.\"\"\"\n",
        "        while self.count_tokens() > self.max_tokens and len(self.messages) > 2:\n",
        "            # Keep system prompt, remove oldest user/assistant pair\n",
        "            if len(self.messages) > 1:\n",
        "                self.messages.pop(1)  # Remove second message (first after system)\n",
        "    \n",
        "    def send(self, user_message: str) -> str:\n",
        "        \"\"\"Send message with automatic history management.\"\"\"\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        \n",
        "        # Trim if needed\n",
        "        self.trim_history()\n",
        "        \n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=self.messages\n",
        "        )\n",
        "        \n",
        "        assistant_message = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        \n",
        "        return assistant_message\n\n",
        "# Test with token tracking\n",
        "smart_conv = SmartConversationManager(max_tokens=200)  # Very small for demo\n",
        "\n",
        "for i in range(5):\n",
        "    response = smart_conv.send(f\"Tell me a fact about number {i}.\")\n",
        "    print(f\"Turn {i+1}: {smart_conv.count_tokens()} tokens\")\n",
        "    \n",
        "print(f\"\\nFinal message count: {len(smart_conv.messages)}\")\n",
        "print(\"(Old messages were automatically removed!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversation State Patterns\n\n",
        "### Pattern 1: Stateful Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PersonalityBot:\n",
        "    \"\"\"Chatbot with persistent personality.\"\"\"\n",
        "    def __init__(self, personality: str):\n",
        "        self.conversation = ConversationManager(\n",
        "            system_prompt=f\"You are a chatbot with this personality: {personality}\"\n",
        "        )\n",
        "        self.turn_count = 0\n",
        "    \n",
        "    def chat(self, message: str) -> str:\n",
        "        self.turn_count += 1\n",
        "        response = self.conversation.send(message)\n",
        "        print(f\"[Turn {self.turn_count}]\")\n",
        "        print(f\"You: {message}\")\n",
        "        print(f\"Bot: {response}\\n\")\n",
        "        return response\n\n",
        "# Create a pirate bot!\n",
        "bot = PersonalityBot(\"You are a friendly pirate who says 'arr' frequently.\")\n\n",
        "bot.chat(\"Hello!\")\n",
        "bot.chat(\"What's your favorite food?\")\n",
        "bot.chat(\"Tell me about the sea.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pattern 2: Save/Load Conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n\n",
        "class PersistentConversation:\n",
        "    \"\"\"Conversation that can be saved and loaded.\"\"\"\n",
        "    def __init__(self, filepath: str = None):\n",
        "        self.filepath = filepath\n",
        "        self.conversation = ConversationManager()\n",
        "        \n",
        "        if filepath and os.path.exists(filepath):\n",
        "            self.load()\n",
        "    \n",
        "    def save(self):\n",
        "        \"\"\"Save conversation to file.\"\"\"\n",
        "        with open(self.filepath, 'w') as f:\n",
        "            json.dump(self.conversation.messages, f, indent=2)\n",
        "        print(f\"ðŸ’¾ Saved to {self.filepath}\")\n",
        "    \n",
        "    def load(self):\n",
        "        \"\"\"Load conversation from file.\"\"\"\n",
        "        with open(self.filepath, 'r') as f:\n",
        "            self.conversation.messages = json.load(f)\n",
        "        print(f\"ðŸ“‚ Loaded from {self.filepath}\")\n",
        "    \n",
        "    def chat(self, message: str) -> str:\n",
        "        response = self.conversation.send(message)\n",
        "        if self.filepath:\n",
        "            self.save()  # Auto-save after each message\n",
        "        return response\n\n",
        "# Example usage\n",
        "conv = PersistentConversation(\"my_conversation.json\")\n",
        "conv.chat(\"Remember, my favorite color is blue.\")\n",
        "conv.chat(\"What's my favorite color?\")\n\n",
        "# Later, you can reload and continue\n",
        "# new_session = PersistentConversation(\"my_conversation.json\")\n",
        "# new_session.chat(\"Do you remember my favorite color?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices\n\n",
        "### 1. Always include system prompt\n",
        "```python\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Your behavior instructions\"},\n",
        "    # ... conversation\n",
        "]\n",
        "```\n\n",
        "### 2. Track token usage\n",
        "```python\n",
        "total_tokens = sum(len(encoding.encode(msg['content'])) for msg in messages)\n",
        "```\n\n",
        "### 3. Implement context window limits\n",
        "Don't let conversations grow unbounded!\n\n",
        "### 4. Handle errors gracefully\n",
        "```python\n",
        "try:\n",
        "    response = client.chat.completions.create(...)\n",
        "except Exception as e:\n",
        "    # Handle error, maybe retry\n",
        "```\n\n",
        "### 5. Consider conversation summarization\n",
        "For very long conversations, periodically summarize and start fresh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice Exercises\n\n",
        "1. Build a chatbot that remembers user preferences across multiple turns\n",
        "2. Implement a conversation manager that keeps only the last 5 message pairs\n",
        "3. Create a bot that tracks how many turns have passed and mentions it\n",
        "4. Build a Q&A bot that references previous questions in its answers\n",
        "5. Implement conversation branching (save state, try different paths)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
