{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LLM Terminology\n\n## Core Concepts\n\n### AI vs AGI\n- **AI (Artificial Intelligence)**: Systems that perform tasks requiring intelligence\n- **Narrow AI**: Specialized for specific tasks (what we have today)\n- **AGI (Artificial General Intelligence)**: Human-level intelligence across all domains (not yet achieved)\n\n### LLM (Large Language Model)\n- Neural network trained on massive text data\n- Predicts next token based on context\n- Billions of parameters (GPT-4: estimated 1.7T)\n\n### Key Terms\n\n**Token:**\n- Unit of text (roughly 0.75 words)\n- \"Hello world\" = ~2 tokens\n- Pricing is per token\n\n**Context Window:**\n- Maximum tokens model can process\n- GPT-3.5: 16k tokens (~12k words)\n- GPT-4 Turbo: 128k tokens (~96k words)\n\n**Temperature (0.0-2.0):**\n- Controls randomness\n- 0 = deterministic, focused\n- 1 = balanced creativity\n- 2 = very random, creative\n\n**Top-p (0.0-1.0):**\n- Nucleus sampling\n- Considers tokens with cumulative probability p\n- Alternative to temperature\n\n**Inference:**\n- Running model to generate output\n- \"API call\" = inference\n\n**Training:**\n- Teaching model from data\n- You don't do this with pre-trained models\n- Fine-tuning = additional training\n\n**Prompt:**\n- Input text to the model\n- \"User message\" in API\n\n**Completion:**\n- Output text from model\n- \"Assistant message\" in API\n\n## Parameters Summary\n\n| Parameter | Range | Effect | Default |\n|-----------|-------|--------|--------|\n| temperature | 0-2 | Randomness | 1.0 |\n| max_tokens | 1-4096+ | Length limit | None |\n| top_p | 0-1 | Nucleus sampling | 1.0 |\n| frequency_penalty | -2 to 2 | Reduce repetition | 0 |\n| presence_penalty | -2 to 2 | Encourage new topics | 0 |"]}], "metadata": {"kernelspec": {"display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 4}
