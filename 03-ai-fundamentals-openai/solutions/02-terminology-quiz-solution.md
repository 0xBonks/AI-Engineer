# Solution: AI & LLM Terminology Quiz

## Part 1: Definitions (20 points)

### 1. What is a token? (2 points)
**Answer:**
A token is the basic unit of text that LLMs process. It can be a word, part of a word, or punctuation. On average, 1 token ≈ 0.75 words (or 1 word ≈ 1.33 tokens). For example, "Hello world!" might be 3 tokens: ["Hello", " world", "!"].

**Grading:** 
- Full credit (2pts): Mentions it's a unit of text and relationship to words
- Partial credit (1pt): Only mentions unit of text without examples

---

### 2. Explain the difference between AI and AGI. (2 points)
**Answer:**
- **AI (Artificial Intelligence):** Systems that perform tasks requiring intelligence. Today's AI is "narrow AI" - specialized for specific tasks (like image recognition, language processing, game playing).
- **AGI (Artificial General Intelligence):** Hypothetical AI with human-level intelligence across ALL domains - can learn, reason, and adapt to any task like a human. AGI does not yet exist.

**Grading:**
- Full credit (2pts): Clearly distinguishes narrow vs general intelligence
- Partial credit (1pt): Mentions both but lacks clarity on "narrow" vs "general"

---

### 3. What is a context window? (2 points)
**Answer:**
The context window is the maximum number of tokens (input + output combined) that a model can process in a single request. For example, GPT-3.5 has a 16k token context window, meaning the sum of your prompt and the model's response cannot exceed 16,000 tokens.

**Grading:**
- Full credit (2pts): Mentions max tokens AND that it includes both input and output
- Partial credit (1pt): Mentions max tokens but doesn't clarify input+output

---

### 4. What does "inference" mean in the context of LLMs? (2 points)
**Answer:**
Inference is the process of running a trained model to generate outputs (predictions). When you make an API call to generate text, that's inference - the model is inferring/predicting what text should come next based on your input. This is different from training, which is teaching the model from data.

**Grading:**
- Full credit (2pts): Mentions running model to generate outputs
- Partial credit (1pt): Vague understanding but not precise

---

### 5. Explain the difference between pre-training and fine-tuning. (2 points)
**Answer:**
- **Pre-training:** The initial training of a model on massive, diverse datasets (like GPT-4's training on internet text). This is expensive, takes months, and is done by the model provider.
- **Fine-tuning:** Additional training on a smaller, specialized dataset to adapt the model for specific tasks or styles. Much cheaper and faster than pre-training from scratch.

**Grading:**
- Full credit (2pts): Clearly distinguishes initial training vs specialized adaptation
- Partial credit (1pt): Mentions both but unclear on the difference

---

### 6. What is temperature and how does it affect outputs? (2 points)
**Answer:**
Temperature (0.0 to 2.0) controls the randomness of model outputs:
- **Low temperature (0.0-0.3):** Deterministic, focused, predictable responses. Same prompt → similar outputs.
- **Medium temperature (~1.0):** Balanced creativity and consistency
- **High temperature (1.5-2.0):** Random, creative, diverse responses. Same prompt → very different outputs.

**Grading:**
- Full credit (2pts): Explains randomness AND gives example of low vs high
- Partial credit (1pt): Only mentions randomness without examples

---

### 7. What is top-p sampling? (2 points)
**Answer:**
Top-p (nucleus sampling) is an alternative to temperature for controlling randomness. Instead of considering all possible tokens, the model only considers the smallest set of tokens whose cumulative probability reaches p. For example, top-p=0.9 means "consider only tokens that make up the top 90% probability mass."

**Grading:**
- Full credit (2pts): Mentions cumulative probability and what it does
- Partial credit (1pt): Vague understanding of "sampling method"

---

### 8. What is a prompt? (2 points)
**Answer:**
A prompt is the input text you send to an LLM. It's your instruction, question, or context that tells the model what to generate. In the OpenAI API, prompts are sent as "user" messages (along with optional "system" messages for behavior instructions).

**Grading:**
- Full credit (2pts): Clear that it's the input/instruction to the model
- Partial credit (1pt): Too vague

---

### 9. What is a completion? (2 points)
**Answer:**
A completion is the output text generated by the model in response to your prompt. It's the model's "answer" or generated content. In the OpenAI API, completions are returned as "assistant" messages.

**Grading:**
- Full credit (2pts): Clear that it's the model's output/response
- Partial credit (1pt): Vague or incomplete

---

### 10. How many words is approximately 1000 tokens? (2 points)
**Answer:**
Approximately 750 words. 

**Calculation:** 1 token ≈ 0.75 words, so 1000 tokens × 0.75 = 750 words

**Grading:**
- Full credit (2pts): Answer in range 700-800 words
- Partial credit (1pt): Answer in range 600-900 words
- No credit: Outside this range

---

## Part 2: Multiple Choice (15 points)

### 11. Which temperature setting produces the most deterministic outputs?
**Answer: a) 0.0** ✓

*Explanation:* Temperature 0 produces the most predictable, focused outputs. The model always chooses the highest probability token.

---

### 12. GPT-4's approximate parameter count is:
**Answer: c) 1.7 trillion** ✓

*Explanation:* GPT-4 has approximately 1.7 trillion parameters (unconfirmed by OpenAI but widely reported). GPT-3 was 175 billion.

---

### 13. Which model has the largest context window?
**Answer: d) Gemini Pro (1M tokens)** ✓

*Explanation:* As of 2024, Gemini Pro's 1 million token context is the largest publicly available. Claude has 200k, GPT-4 Turbo has 128k.

---

### 14. What does a higher frequency_penalty do?
**Answer: c) Reduces word repetition** ✓

*Explanation:* Frequency penalty reduces the likelihood of repeating tokens that already appeared. Higher values = less repetition.

---

### 15. Which statement about pre-trained models is FALSE?
**Answer: b) They can learn from conversations** ✓

*Explanation:* Pre-trained models do NOT learn from individual conversations. Each API call is stateless. The model's knowledge is fixed from training.

---

## Part 3: Calculations (10 points)

### 16. Token Calculation (5 points)
**Calculation:**
- 1 word ≈ 1.33 tokens (or 1 token ≈ 0.75 words)
- 500 words × 1.33 = 665 tokens

**Answer: ~665-670 tokens**

**Grading:**
- Full credit (5pts): Answer 650-700 tokens with correct calculation shown
- Partial credit (3pts): Answer in range but calculation unclear
- Partial credit (1pt): Wrong answer but showed attempt at calculation

---

### 17. Cost Calculation (5 points)
**Input cost calculation:**
- 1000 calls × 100 tokens = 100,000 input tokens = 100k tokens
- 100k tokens ÷ 1000 = 100 "1k token units"
- 100 × $0.0015 = $0.15

**Output cost calculation:**
- 1000 calls × 200 tokens = 200,000 output tokens = 200k tokens
- 200k tokens ÷ 1000 = 200 "1k token units"
- 200 × $0.002 = $0.40

**Total cost: $0.15 + $0.40 = $0.55**

**Grading:**
- Full credit (5pts): Correct answer ($0.55) with clear calculation
- Partial credit (3pts): Right method but minor math error
- Partial credit (1pt): Attempted calculation but significant errors

---

## Part 4: Scenarios (15 points)

### 18. When to use temperature 0.0? (5 points)
**Example answers (any 3 valid):**

1. **Data extraction** - Need consistent, predictable extraction of structured data (names, dates, prices)
2. **Code generation** - Want deterministic, working code without random variations
3. **Factual Q&A** - Need the most accurate, focused answer without creative variations
4. **Classification tasks** - Need consistent categorization (sentiment analysis, topic classification)
5. **Mathematical calculations** - Need precise, correct answers
6. **Legal/medical applications** - Cannot afford random variations in critical domains

**Grading:**
- Full credit (5pts): 3 valid use cases with clear reasoning
- Partial credit (3pts): 2 valid use cases
- Partial credit (1pt): 1 valid use case

---

### 19. When to use high temperature (1.5-2.0)? (5 points)
**Example answers (any 3 valid):**

1. **Creative writing** - Stories, poetry, imaginative content where variety is desired
2. **Brainstorming ideas** - Want diverse, unexpected suggestions
3. **Marketing copy variations** - Generate many different angles for A/B testing
4. **Character dialogue** - Make conversations more natural and varied
5. **Artistic content** - Song lyrics, creative descriptions, unique perspectives
6. **Exploration tasks** - When you want to discover unexpected approaches

**Grading:**
- Full credit (5pts): 3 valid use cases with clear reasoning
- Partial credit (3pts): 2 valid use cases
- Partial credit (1pt): 1 valid use case

---

### 20. Context Window Planning (5 points)
**Calculation:**

Total available context: 16,000 tokens
System prompt: 200 tokens
Remaining: 16,000 - 200 = 15,800 tokens

Per conversation turn:
- User message: 50 tokens
- Assistant response: 150 tokens
- Total per turn: 200 tokens

Maximum turns: 15,800 ÷ 200 = 79 turns

**However**, practical limit is lower because:
- Need to leave room for the final assistant response
- Usually want buffer of ~10%
- Practical answer: **70-75 turns**

**Answer: 70-79 turns** (with caveat about practical limits)

**Grading:**
- Full credit (5pts): Correct calculation (70-79) with reasoning about practical limits
- Partial credit (3pts): Correct math but no mention of practical considerations
- Partial credit (2pts): Calculation attempted but errors in math
- Partial credit (1pt): Shows understanding of the concept but wrong approach

---

## Part 5: True/False (10 points)

21. **FALSE** - Tokens can be parts of words (subwords) or punctuation, not just whole words
22. **TRUE** - Higher temperature increases randomness/creativity
23. **FALSE** - LLMs don't have internet access by default (knowledge cutoff at training)
24. **TRUE** - Fine-tuning adjusts the model's weights through additional training
25. **TRUE** - Both parameters can be used together (though often just one is used)
26. **FALSE** - Different models have very different costs (GPT-4 20x more than GPT-3.5)
27. **TRUE** - Context window is total: prompt + completion tokens
28. **FALSE** - Parameters are model weights (billions), tokens are text units (consumed per request)
29. **FALSE** - Training requires vastly more compute than inference
30. **TRUE** - Good prompts can dramatically improve outputs without any model changes

**Grading:** 1 point each, total 10 points

---

## Scoring Summary

- **54-60 points:** Excellent! Strong grasp of LLM concepts
- **45-53 points:** Good! Minor gaps to review
- **36-44 points:** Fair. Review notebooks again
- **Below 36:** Need to study material more thoroughly

---

## Key Concepts to Remember

1. **Tokens ≈ 0.75 words** - Essential for cost calculations
2. **Temperature controls randomness** - 0 = deterministic, 2 = creative
3. **Context window = input + output** - Must plan for both
4. **Pre-trained models don't learn** - Each call is independent
5. **Different models have vastly different costs** - Choose appropriately
6. **Parameters ≠ tokens** - Parameters are model size, tokens are usage
7. **Fine-tuning changes weights** - Unlike prompt engineering
8. **LLMs have knowledge cutoffs** - No real-time data access
